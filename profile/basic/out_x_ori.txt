Using device: cuda
Preparation time: 31.04368019104004 ms
		Step preparation time: 0.08883199840784073 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 935.2559204101562 ms
		Gumbel noise and sampling time: 3.99564790725708 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 19.142431259155273 ms
			Confidence score gathering time: 4.834239959716797 ms
		Confidence score calculation time: 24.10905647277832 ms
		Apply predictions where we have masks time: 12.387200355529785 ms
		Find transfer index time: 0.19660800695419312 ms
			Selecting transfer indices time (topk): 18.257919311523438 ms
			Applying transfer index time (where transfer_index): 0.05532800033688545 ms
		update token time: 18.41766357421875 ms
		Step preparation time: 0.07049600034952164 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 75.07894134521484 ms
		Gumbel noise and sampling time: 0.17510400712490082 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.06118392944336 ms
			Confidence score gathering time: 0.07372800260782242 ms
		Confidence score calculation time: 8.247296333312988 ms
		Apply predictions where we have masks time: 0.10956799983978271 ms
		Find transfer index time: 0.08396799862384796 ms
			Selecting transfer indices time (topk): 2.1164159774780273 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 2.238464117050171 ms
		Step preparation time: 0.055776000022888184 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.25788879394531 ms
		Gumbel noise and sampling time: 0.17215999960899353 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9185919761657715 ms
			Confidence score gathering time: 0.062431998550891876 ms
		Confidence score calculation time: 8.084480285644531 ms
		Apply predictions where we have masks time: 0.09600000083446503 ms
		Find transfer index time: 0.0809599980711937 ms
			Selecting transfer indices time (topk): 1.0885119438171387 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2049599885940552 ms
		Step preparation time: 0.05471999943256378 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.54476928710938 ms
		Gumbel noise and sampling time: 0.16867199540138245 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.858176231384277 ms
			Confidence score gathering time: 0.054048001766204834 ms
		Confidence score calculation time: 8.013824462890625 ms
		Apply predictions where we have masks time: 0.09523200243711472 ms
		Find transfer index time: 0.07254400104284286 ms
			Selecting transfer indices time (topk): 1.141759991645813 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.2728320360183716 ms
		Step preparation time: 0.0541439987719059 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.21971130371094 ms
		Gumbel noise and sampling time: 0.1730560064315796 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.919583797454834 ms
			Confidence score gathering time: 0.060416001826524734 ms
		Confidence score calculation time: 8.1080322265625 ms
		Apply predictions where we have masks time: 0.11264000087976456 ms
		Find transfer index time: 0.08300799876451492 ms
			Selecting transfer indices time (topk): 1.2288000583648682 ms
			Applying transfer index time (where transfer_index): 0.03788800165057182 ms
		update token time: 1.363968014717102 ms
		Step preparation time: 0.06128000095486641 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.71836853027344 ms
		Gumbel noise and sampling time: 0.16675199568271637 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.862080097198486 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.01587200164795 ms
		Apply predictions where we have masks time: 0.09628800302743912 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.106943964958191 ms
			Applying transfer index time (where transfer_index): 0.03296000137925148 ms
		update token time: 1.2247040271759033 ms
		Step preparation time: 0.05398400127887726 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.15628814697266 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.058368001133203506 ms
		Confidence score calculation time: 8.073216438293457 ms
		Apply predictions where we have masks time: 0.09504000097513199 ms
		Find transfer index time: 0.07184000313282013 ms
			Selecting transfer indices time (topk): 1.0915839672088623 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.21343994140625 ms
		Step preparation time: 0.05471999943256378 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.06444549560547 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.05305600166320801 ms
		Confidence score calculation time: 8.068096160888672 ms
		Apply predictions where we have masks time: 0.09542399644851685 ms
		Find transfer index time: 0.07081600278615952 ms
			Selecting transfer indices time (topk): 1.097599983215332 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.2134720087051392 ms
		Step preparation time: 0.05369599908590317 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.26588439941406 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.916543960571289 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.069120407104492 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.0957119464874268 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.218559980392456 ms
		Step preparation time: 0.05443200096487999 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.87667083740234 ms
		Gumbel noise and sampling time: 0.16777600347995758 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.916543960571289 ms
			Confidence score gathering time: 0.052352000027894974 ms
		Confidence score calculation time: 8.070143699645996 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07782399654388428 ms
			Selecting transfer indices time (topk): 1.112064003944397 ms
			Applying transfer index time (where transfer_index): 0.03187200054526329 ms
		update token time: 1.2286399602890015 ms
		Step preparation time: 0.05475199967622757 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.26844787597656 ms
		Gumbel noise and sampling time: 0.1658879965543747 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.05119999870657921 ms
		Confidence score calculation time: 8.062975883483887 ms
		Apply predictions where we have masks time: 0.09625600278377533 ms
		Find transfer index time: 0.0716480016708374 ms
			Selecting transfer indices time (topk): 1.1008000373840332 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2226879596710205 ms
		Step preparation time: 0.05430399999022484 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.93405151367188 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.071264266967773 ms
		Apply predictions where we have masks time: 0.09728000313043594 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.1008000373840332 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.218559980392456 ms
		Step preparation time: 0.0541439987719059 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.36329650878906 ms
		Gumbel noise and sampling time: 0.18636800348758698 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.0530879981815815 ms
		Confidence score calculation time: 8.069120407104492 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07782399654388428 ms
			Selecting transfer indices time (topk): 1.07315194606781 ms
			Applying transfer index time (where transfer_index): 0.03270399942994118 ms
		update token time: 1.1888959407806396 ms
		Step preparation time: 0.05427199974656105 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.87532806396484 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.052352000027894974 ms
		Confidence score calculation time: 8.072192192077637 ms
		Apply predictions where we have masks time: 0.09542399644851685 ms
		Find transfer index time: 0.0708480030298233 ms
			Selecting transfer indices time (topk): 1.094655990600586 ms
			Applying transfer index time (where transfer_index): 0.035840000957250595 ms
		update token time: 1.2288639545440674 ms
		Step preparation time: 0.0533440001308918 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.3377914428711 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.947264194488525 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.09881591796875 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.078015998005867 ms
			Selecting transfer indices time (topk): 1.077247977256775 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.1929600238800049 ms
		Step preparation time: 0.05459199845790863 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.00672149658203 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.8592000007629395 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.011775970458984 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.0741759538650513 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.1898880004882812 ms
		Step preparation time: 0.05446400120854378 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.35929870605469 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.050335999578237534 ms
		Confidence score calculation time: 8.065024375915527 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.06496000289917 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.183743953704834 ms
		Step preparation time: 0.054687999188899994 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.74793243408203 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.916543960571289 ms
			Confidence score gathering time: 0.05939200147986412 ms
		Confidence score calculation time: 8.078304290771484 ms
		Apply predictions where we have masks time: 0.09625600278377533 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.0792959928512573 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.1970560550689697 ms
		Step preparation time: 0.05500800162553787 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.60163116455078 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9134721755981445 ms
			Confidence score gathering time: 0.058400001376867294 ms
		Confidence score calculation time: 8.074111938476562 ms
		Apply predictions where we have masks time: 0.08921600133180618 ms
		Find transfer index time: 0.08006399869918823 ms
			Selecting transfer indices time (topk): 1.077280044555664 ms
			Applying transfer index time (where transfer_index): 0.03267199918627739 ms
		update token time: 1.1980799436569214 ms
		Step preparation time: 0.05804799869656563 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.88690948486328 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.08243179321289 ms
		Apply predictions where we have masks time: 0.09196799993515015 ms
		Find transfer index time: 0.07081600278615952 ms
			Selecting transfer indices time (topk): 1.099776029586792 ms
			Applying transfer index time (where transfer_index): 0.03187200054526329 ms
		update token time: 1.2166399955749512 ms
		Step preparation time: 0.05555199831724167 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.7384033203125 ms
		Gumbel noise and sampling time: 0.1658879965543747 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.913536071777344 ms
			Confidence score gathering time: 0.052352000027894974 ms
		Confidence score calculation time: 8.068096160888672 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.0782719850540161 ms
			Applying transfer index time (where transfer_index): 0.032735999673604965 ms
		update token time: 1.1949440240859985 ms
		Step preparation time: 0.0551999993622303 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.78594970703125 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915487766265869 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.069120407104492 ms
		Apply predictions where we have masks time: 0.09523200243711472 ms
		Find transfer index time: 0.07983999699354172 ms
			Selecting transfer indices time (topk): 1.0864640474319458 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2052479982376099 ms
		Step preparation time: 0.054687999188899994 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.78409576416016 ms
		Gumbel noise and sampling time: 0.16883200407028198 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.067071914672852 ms
		Apply predictions where we have masks time: 0.09622400254011154 ms
		Find transfer index time: 0.06963200122117996 ms
			Selecting transfer indices time (topk): 1.0864640474319458 ms
			Applying transfer index time (where transfer_index): 0.03283200040459633 ms
		update token time: 1.2072960138320923 ms
		Step preparation time: 0.05536000058054924 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.38764953613281 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.077152252197266 ms
		Apply predictions where we have masks time: 0.09017600119113922 ms
		Find transfer index time: 0.07782399654388428 ms
			Selecting transfer indices time (topk): 1.183743953704834 ms
			Applying transfer index time (where transfer_index): 0.033663999289274216 ms
		update token time: 1.3005759716033936 ms
		Step preparation time: 0.055776000022888184 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.78768157958984 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.067071914672852 ms
		Apply predictions where we have masks time: 0.10342399775981903 ms
		Find transfer index time: 0.070592001080513 ms
			Selecting transfer indices time (topk): 1.1233279705047607 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2410880327224731 ms
		Step preparation time: 0.05462399870157242 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.27619171142578 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.052032001316547394 ms
		Confidence score calculation time: 8.069120407104492 ms
		Apply predictions where we have masks time: 0.08908800035715103 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.1038719415664673 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2247040271759033 ms
		Step preparation time: 0.05491200089454651 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.02627563476562 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914303779602051 ms
			Confidence score gathering time: 0.05119999870657921 ms
		Confidence score calculation time: 8.066047668457031 ms
		Apply predictions where we have masks time: 0.09827200323343277 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.1192320585250854 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2369920015335083 ms
		Step preparation time: 0.054976001381874084 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.3941421508789 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.945216178894043 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.09881591796875 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07999999821186066 ms
			Selecting transfer indices time (topk): 1.1612160205841064 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2799999713897705 ms
		Step preparation time: 0.054976001381874084 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.33379364013672 ms
		Gumbel noise and sampling time: 0.16784000396728516 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915328025817871 ms
			Confidence score gathering time: 0.05036799982190132 ms
		Confidence score calculation time: 8.063136100769043 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.1212799549102783 ms
			Applying transfer index time (where transfer_index): 0.03363199904561043 ms
		update token time: 1.2380160093307495 ms
		Step preparation time: 0.05385600030422211 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.49849700927734 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.06656000018119812 ms
		Confidence score calculation time: 8.09164810180664 ms
		Apply predictions where we have masks time: 0.10041599720716476 ms
		Find transfer index time: 0.08700799942016602 ms
			Selecting transfer indices time (topk): 1.2554240226745605 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3721599578857422 ms
		Step preparation time: 0.05484800040721893 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.87715148925781 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.067168235778809 ms
		Apply predictions where we have masks time: 0.09523200243711472 ms
		Find transfer index time: 0.07257600128650665 ms
			Selecting transfer indices time (topk): 1.1201280355453491 ms
			Applying transfer index time (where transfer_index): 0.035840000957250595 ms
		update token time: 1.248255968093872 ms
		Step preparation time: 0.05455999821424484 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.74687957763672 ms
		Gumbel noise and sampling time: 0.16886399686336517 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.068127632141113 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 0.05955199897289276 ms
			Applying transfer index time (where transfer_index): 0.030719999223947525 ms
		update token time: 0.16889600455760956 ms
Block 0 time: 3873.147216796875 ms
		Step preparation time: 0.05894400179386139 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.81334686279297 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.06492805480957 ms
			Confidence score gathering time: 0.05648000165820122 ms
		Confidence score calculation time: 8.232799530029297 ms
		Apply predictions where we have masks time: 0.1085439994931221 ms
		Find transfer index time: 0.07366400212049484 ms
			Selecting transfer indices time (topk): 3.0361599922180176 ms
			Applying transfer index time (where transfer_index): 0.03299200162291527 ms
		update token time: 3.155967950820923 ms
		Step preparation time: 0.05510399863123894 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.97923278808594 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.91542387008667 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.072352409362793 ms
		Apply predictions where we have masks time: 0.0942080020904541 ms
		Find transfer index time: 0.07475200295448303 ms
			Selecting transfer indices time (topk): 1.2738560438156128 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3906240463256836 ms
		Step preparation time: 0.055135998874902725 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.33856201171875 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9584641456604 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.113151550292969 ms
		Apply predictions where we have masks time: 0.09200000017881393 ms
		Find transfer index time: 0.07366400212049484 ms
			Selecting transfer indices time (topk): 1.2390400171279907 ms
			Applying transfer index time (where transfer_index): 0.03267199918627739 ms
		update token time: 1.3549439907073975 ms
		Step preparation time: 0.055135998874902725 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.13468933105469 ms
		Gumbel noise and sampling time: 0.17286400496959686 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.917471885681152 ms
			Confidence score gathering time: 0.058368001133203506 ms
		Confidence score calculation time: 8.078304290771484 ms
		Apply predictions where we have masks time: 0.10547199845314026 ms
		Find transfer index time: 0.07680000364780426 ms
			Selecting transfer indices time (topk): 1.7375359535217285 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.8575359582901 ms
		Step preparation time: 0.057792000472545624 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.66649627685547 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914463996887207 ms
			Confidence score gathering time: 0.055296000093221664 ms
		Confidence score calculation time: 8.070143699645996 ms
		Apply predictions where we have masks time: 0.09523200243711472 ms
		Find transfer index time: 0.07583999633789062 ms
			Selecting transfer indices time (topk): 1.5255999565124512 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.6414719820022583 ms
		Step preparation time: 0.06348799914121628 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.37350463867188 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.055424001067876816 ms
		Confidence score calculation time: 8.072192192077637 ms
		Apply predictions where we have masks time: 0.0931520015001297 ms
		Find transfer index time: 0.0745600014925003 ms
			Selecting transfer indices time (topk): 1.4172159433364868 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.5349760055541992 ms
		Step preparation time: 0.05603199824690819 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.98809814453125 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.055135998874902725 ms
		Confidence score calculation time: 8.072192192077637 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.3271039724349976 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.45305597782135 ms
		Step preparation time: 0.05721599981188774 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.21683502197266 ms
		Gumbel noise and sampling time: 0.17190399765968323 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.928832054138184 ms
			Confidence score gathering time: 0.05734400078654289 ms
		Confidence score calculation time: 8.086527824401855 ms
		Apply predictions where we have masks time: 0.10649599879980087 ms
		Find transfer index time: 0.07577600330114365 ms
			Selecting transfer indices time (topk): 1.4970879554748535 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.6147520542144775 ms
		Step preparation time: 0.05612799897789955 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 75.2929916381836 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.054048001766204834 ms
		Confidence score calculation time: 8.070143699645996 ms
		Apply predictions where we have masks time: 0.09430400282144547 ms
		Find transfer index time: 0.0737600028514862 ms
			Selecting transfer indices time (topk): 1.528831958770752 ms
			Applying transfer index time (where transfer_index): 0.032575998455286026 ms
		update token time: 1.651487946510315 ms
		Step preparation time: 0.05548800155520439 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.89462280273438 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.05244800075888634 ms
		Confidence score calculation time: 8.070079803466797 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07155200093984604 ms
			Selecting transfer indices time (topk): 1.4008320569992065 ms
			Applying transfer index time (where transfer_index): 0.03359999880194664 ms
		update token time: 1.5176960229873657 ms
		Step preparation time: 0.05587200075387955 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.72220611572266 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973023891448975 ms
			Confidence score gathering time: 0.05337600037455559 ms
		Confidence score calculation time: 8.129535675048828 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.2769919633865356 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3946880102157593 ms
		Step preparation time: 0.05711999908089638 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.17782592773438 ms
		Gumbel noise and sampling time: 0.16777600347995758 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9152960777282715 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.070143699645996 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.3332480192184448 ms
			Applying transfer index time (where transfer_index): 0.03270399942994118 ms
		update token time: 1.4499839544296265 ms
		Step preparation time: 0.05503999814391136 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.63520050048828 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.0522879995405674 ms
		Confidence score calculation time: 8.125439643859863 ms
		Apply predictions where we have masks time: 0.0942080020904541 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.3527040481567383 ms
			Applying transfer index time (where transfer_index): 0.0318400003015995 ms
		update token time: 1.46943998336792 ms
		Step preparation time: 0.05539200082421303 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.25091552734375 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.068160057067871 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.2759040594100952 ms
			Applying transfer index time (where transfer_index): 0.05632000043988228 ms
		update token time: 1.4213119745254517 ms
		Step preparation time: 0.05510399863123894 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.90096282958984 ms
		Gumbel noise and sampling time: 0.16780799627304077 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.053279999643564224 ms
		Confidence score calculation time: 8.068096160888672 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07260800153017044 ms
			Selecting transfer indices time (topk): 1.2595200538635254 ms
			Applying transfer index time (where transfer_index): 0.05632000043988228 ms
		update token time: 1.411072015762329 ms
		Step preparation time: 0.05615999922156334 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.42205047607422 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.068096160888672 ms
		Apply predictions where we have masks time: 0.09324800223112106 ms
		Find transfer index time: 0.07177600264549255 ms
			Selecting transfer indices time (topk): 1.2552319765090942 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3722560405731201 ms
		Step preparation time: 0.0568000003695488 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.17362976074219 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.068191528320312 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07283200323581696 ms
			Selecting transfer indices time (topk): 1.274880051612854 ms
			Applying transfer index time (where transfer_index): 0.03385600075125694 ms
		update token time: 1.4183039665222168 ms
		Step preparation time: 0.05491200089454651 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.52009582519531 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.944191932678223 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.09984016418457 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07171200215816498 ms
			Selecting transfer indices time (topk): 1.3496320247650146 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.4663679599761963 ms
		Step preparation time: 0.05478399991989136 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.09209442138672 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.052352000027894974 ms
		Confidence score calculation time: 8.070143699645996 ms
		Apply predictions where we have masks time: 0.09404800087213516 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.4684799909591675 ms
			Applying transfer index time (where transfer_index): 0.03190400078892708 ms
		update token time: 1.5882240533828735 ms
		Step preparation time: 0.0549440011382103 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.92115020751953 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.917568206787109 ms
			Confidence score gathering time: 0.05225599929690361 ms
		Confidence score calculation time: 8.071167945861816 ms
		Apply predictions where we have masks time: 0.0942080020904541 ms
		Find transfer index time: 0.07177600264549255 ms
			Selecting transfer indices time (topk): 1.3475840091705322 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.4673919677734375 ms
		Step preparation time: 0.054336000233888626 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.55503845214844 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.052352000027894974 ms
		Confidence score calculation time: 8.127552032470703 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.265663981437683 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.384544014930725 ms
		Step preparation time: 0.05615999922156334 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.26518249511719 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.070015907287598 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.0799039974808693 ms
			Selecting transfer indices time (topk): 1.1766079664230347 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.2922879457473755 ms
		Step preparation time: 0.05510399863123894 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.91088104248047 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05721599981188774 ms
		Confidence score calculation time: 8.138751983642578 ms
		Apply predictions where we have masks time: 0.0942080020904541 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.2606079578399658 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.3875839710235596 ms
		Step preparation time: 0.056384000927209854 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.2232666015625 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05318399891257286 ms
		Confidence score calculation time: 8.125439643859863 ms
		Apply predictions where we have masks time: 0.09200000017881393 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.2104640007019043 ms
			Applying transfer index time (where transfer_index): 0.032607998698949814 ms
		update token time: 1.3271039724349976 ms
		Step preparation time: 0.05452800169587135 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.18854522705078 ms
		Gumbel noise and sampling time: 0.16892799735069275 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.0541439987719059 ms
		Confidence score calculation time: 8.069120407104492 ms
		Apply predictions where we have masks time: 0.09228800237178802 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.217471957206726 ms
			Applying transfer index time (where transfer_index): 0.03267199918627739 ms
		update token time: 1.3332480192184448 ms
		Step preparation time: 0.05644800141453743 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.67375946044922 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.05632000043988228 ms
		Confidence score calculation time: 8.139776229858398 ms
		Apply predictions where we have masks time: 0.09513600170612335 ms
		Find transfer index time: 0.07475200295448303 ms
			Selecting transfer indices time (topk): 1.2810560464859009 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3998080492019653 ms
		Step preparation time: 0.061983998864889145 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.98182678222656 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915359973907471 ms
			Confidence score gathering time: 0.060416001826524734 ms
		Confidence score calculation time: 8.088576316833496 ms
		Apply predictions where we have masks time: 0.10342399775981903 ms
		Find transfer index time: 0.08089599758386612 ms
			Selecting transfer indices time (topk): 1.4663679599761963 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.6047999858856201 ms
		Step preparation time: 0.06063999980688095 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.09635162353516 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.917568206787109 ms
			Confidence score gathering time: 0.0533440001308918 ms
		Confidence score calculation time: 8.074239730834961 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07276800274848938 ms
			Selecting transfer indices time (topk): 1.2206079959869385 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3373440504074097 ms
		Step preparation time: 0.05536000058054924 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.64134216308594 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.13036823272705 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.2502080202102661 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.368224024772644 ms
		Step preparation time: 0.055904000997543335 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.22284698486328 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.069120407104492 ms
		Apply predictions where we have masks time: 0.09302400052547455 ms
		Find transfer index time: 0.08499199897050858 ms
			Selecting transfer indices time (topk): 1.248255968093872 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.365056037902832 ms
		Step preparation time: 0.05459199845790863 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.92623901367188 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.05318399891257286 ms
		Confidence score calculation time: 8.068096160888672 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.08294399827718735 ms
			Selecting transfer indices time (topk): 1.287168025970459 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.4088959693908691 ms
		Step preparation time: 0.0560000017285347 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.53826904296875 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.984127998352051 ms
			Confidence score gathering time: 0.05417599901556969 ms
		Confidence score calculation time: 8.138688087463379 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 0.05939200147986412 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 0.16896000504493713 ms
Block 1 time: 2954.4541015625 ms
		Step preparation time: 0.058079998940229416 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.4651870727539 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9145917892456055 ms
			Confidence score gathering time: 0.058240000158548355 ms
		Confidence score calculation time: 8.078335762023926 ms
		Apply predictions where we have masks time: 0.09625600278377533 ms
		Find transfer index time: 0.0708480030298233 ms
			Selecting transfer indices time (topk): 2.5506880283355713 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 2.6745920181274414 ms
		Step preparation time: 0.056543998420238495 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.97299194335938 ms
		Gumbel noise and sampling time: 0.17289599776268005 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.07065600156784058 ms
		Confidence score calculation time: 8.167424201965332 ms
		Apply predictions where we have masks time: 0.1228799968957901 ms
		Find transfer index time: 0.07884799689054489 ms
			Selecting transfer indices time (topk): 1.8167359828948975 ms
			Applying transfer index time (where transfer_index): 0.04095999896526337 ms
		update token time: 1.9792959690093994 ms
		Step preparation time: 0.06409599632024765 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.5074234008789 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.964672088623047 ms
			Confidence score gathering time: 0.05411199852824211 ms
		Confidence score calculation time: 8.127488136291504 ms
		Apply predictions where we have masks time: 0.09625600278377533 ms
		Find transfer index time: 0.07468800246715546 ms
			Selecting transfer indices time (topk): 1.7766400575637817 ms
			Applying transfer index time (where transfer_index): 0.033663999289274216 ms
		update token time: 1.8984320163726807 ms
		Step preparation time: 0.05628800019621849 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.45986938476562 ms
		Gumbel noise and sampling time: 0.16681599617004395 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.913440227508545 ms
			Confidence score gathering time: 0.062463998794555664 ms
		Confidence score calculation time: 8.085663795471191 ms
		Apply predictions where we have masks time: 0.1045759990811348 ms
		Find transfer index time: 0.0828159973025322 ms
			Selecting transfer indices time (topk): 1.3945280313491821 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.5124479532241821 ms
		Step preparation time: 0.05491200089454651 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.94745635986328 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915520191192627 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.070143699645996 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07260800153017044 ms
			Selecting transfer indices time (topk): 1.3946880102157593 ms
			Applying transfer index time (where transfer_index): 0.03270399942994118 ms
		update token time: 1.5153919458389282 ms
		Step preparation time: 0.05430399999022484 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.57078552246094 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.982975959777832 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.13871955871582 ms
		Apply predictions where we have masks time: 0.09027200192213058 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.3424639701843262 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.462272047996521 ms
		Step preparation time: 0.0549440011382103 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.4137954711914 ms
		Gumbel noise and sampling time: 0.2170879989862442 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.938047885894775 ms
			Confidence score gathering time: 0.08396799862384796 ms
		Confidence score calculation time: 8.147968292236328 ms
		Apply predictions where we have masks time: 0.15462400019168854 ms
		Find transfer index time: 0.09625600278377533 ms
			Selecting transfer indices time (topk): 2.4883201122283936 ms
			Applying transfer index time (where transfer_index): 0.03481600061058998 ms
		update token time: 2.613248109817505 ms
		Step preparation time: 0.06281600147485733 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.5269775390625 ms
		Gumbel noise and sampling time: 0.1708800047636032 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.2611199915409088 ms
		Confidence score calculation time: 8.648863792419434 ms
		Apply predictions where we have masks time: 0.29286399483680725 ms
		Find transfer index time: 0.18943999707698822 ms
			Selecting transfer indices time (topk): 4.4964799880981445 ms
			Applying transfer index time (where transfer_index): 0.07577600330114365 ms
		update token time: 4.769792079925537 ms
		Step preparation time: 0.0628800019621849 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.44457244873047 ms
		Gumbel noise and sampling time: 0.17510400712490082 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.05939200147986412 ms
		Confidence score calculation time: 8.138751983642578 ms
		Apply predictions where we have masks time: 0.09625600278377533 ms
		Find transfer index time: 0.07782399654388428 ms
			Selecting transfer indices time (topk): 2.514944076538086 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 2.634752035140991 ms
		Step preparation time: 0.06483200192451477 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.12044525146484 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05734400078654289 ms
		Confidence score calculation time: 8.133536338806152 ms
		Apply predictions where we have masks time: 0.0942080020904541 ms
		Find transfer index time: 0.07487999647855759 ms
			Selecting transfer indices time (topk): 1.3086719512939453 ms
			Applying transfer index time (where transfer_index): 0.0326399989426136 ms
		update token time: 1.4275840520858765 ms
		Step preparation time: 0.05711999908089638 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.6827163696289 ms
		Gumbel noise and sampling time: 0.1730560064315796 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.990272045135498 ms
			Confidence score gathering time: 0.05750399827957153 ms
		Confidence score calculation time: 8.152064323425293 ms
		Apply predictions where we have masks time: 0.09830400347709656 ms
		Find transfer index time: 0.07680000364780426 ms
			Selecting transfer indices time (topk): 1.7203199863433838 ms
			Applying transfer index time (where transfer_index): 0.03791999816894531 ms
		update token time: 1.8567039966583252 ms
		Step preparation time: 0.058687999844551086 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.52019500732422 ms
		Gumbel noise and sampling time: 0.17504000663757324 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.917568206787109 ms
			Confidence score gathering time: 0.06348799914121628 ms
		Confidence score calculation time: 8.096832275390625 ms
		Apply predictions where we have masks time: 0.10844799876213074 ms
		Find transfer index time: 0.08499199897050858 ms
			Selecting transfer indices time (topk): 1.6128000020980835 ms
			Applying transfer index time (where transfer_index): 0.03177599981427193 ms
		update token time: 1.7326079607009888 ms
		Step preparation time: 0.05587200075387955 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.99171447753906 ms
		Gumbel noise and sampling time: 0.1812479943037033 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.916543960571289 ms
			Confidence score gathering time: 0.055296000093221664 ms
		Confidence score calculation time: 8.072192192077637 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.4325759410858154 ms
			Applying transfer index time (where transfer_index): 0.03270399942994118 ms
		update token time: 1.5503040552139282 ms
		Step preparation time: 0.05539200082421303 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.71151733398438 ms
		Gumbel noise and sampling time: 0.16979199647903442 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.12441635131836 ms
		Apply predictions where we have masks time: 0.08908800035715103 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.1335680484771729 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2513279914855957 ms
		Step preparation time: 0.05491200089454651 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.14486694335938 ms
		Gumbel noise and sampling time: 0.17084799706935883 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.129535675048828 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.1397119760513306 ms
			Applying transfer index time (where transfer_index): 0.03359999880194664 ms
		update token time: 1.2593920230865479 ms
		Step preparation time: 0.057760000228881836 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.21123504638672 ms
		Gumbel noise and sampling time: 0.17392000555992126 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.0533440001308918 ms
		Confidence score calculation time: 8.069120407104492 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.0855040550231934 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2052479982376099 ms
		Step preparation time: 0.05516799911856651 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.70857238769531 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974944114685059 ms
			Confidence score gathering time: 0.05225599929690361 ms
		Confidence score calculation time: 8.129535675048828 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.2010879516601562 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.3189120292663574 ms
		Step preparation time: 0.062111999839544296 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.05974578857422 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.053119998425245285 ms
		Confidence score calculation time: 8.129440307617188 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.3547840118408203 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.4909440279006958 ms
		Step preparation time: 0.0560000017285347 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.21676635742188 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.914495944976807 ms
			Confidence score gathering time: 0.05833600088953972 ms
		Confidence score calculation time: 8.084480285644531 ms
		Apply predictions where we have masks time: 0.10239999741315842 ms
		Find transfer index time: 0.08003199845552444 ms
			Selecting transfer indices time (topk): 1.2563519477844238 ms
			Applying transfer index time (where transfer_index): 0.03683200106024742 ms
		update token time: 1.3875199556350708 ms
		Step preparation time: 0.061184000223875046 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.8939208984375 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05407999828457832 ms
		Confidence score calculation time: 8.128671646118164 ms
		Apply predictions where we have masks time: 0.09001599997282028 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.2982079982757568 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.418239951133728 ms
		Step preparation time: 0.05337600037455559 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.77753448486328 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.990272045135498 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.149120330810547 ms
		Apply predictions where we have masks time: 0.09523200243711472 ms
		Find transfer index time: 0.07993599772453308 ms
			Selecting transfer indices time (topk): 1.2442879676818848 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.3629440069198608 ms
		Step preparation time: 0.05363199859857559 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.39462280273438 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.97379207611084 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.129535675048828 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.1448320150375366 ms
			Applying transfer index time (where transfer_index): 0.05331199988722801 ms
		update token time: 1.284991979598999 ms
		Step preparation time: 0.05471999943256378 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.99724578857422 ms
		Gumbel noise and sampling time: 0.17817600071430206 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9779839515686035 ms
			Confidence score gathering time: 0.07475200295448303 ms
		Confidence score calculation time: 8.163328170776367 ms
		Apply predictions where we have masks time: 0.1157120019197464 ms
		Find transfer index time: 0.08806400001049042 ms
			Selecting transfer indices time (topk): 2.3347198963165283 ms
			Applying transfer index time (where transfer_index): 0.038047999143600464 ms
		update token time: 2.4678399562835693 ms
		Step preparation time: 0.06780800223350525 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.0014419555664 ms
		Gumbel noise and sampling time: 0.17414399981498718 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.995391845703125 ms
			Confidence score gathering time: 0.07475200295448303 ms
		Confidence score calculation time: 8.180928230285645 ms
		Apply predictions where we have masks time: 0.13811199367046356 ms
		Find transfer index time: 0.11878400295972824 ms
			Selecting transfer indices time (topk): 2.382848024368286 ms
			Applying transfer index time (where transfer_index): 0.0387520007789135 ms
		update token time: 2.519968032836914 ms
		Step preparation time: 0.06668800115585327 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.14559936523438 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.08089599758386612 ms
		Confidence score calculation time: 8.161279678344727 ms
		Apply predictions where we have masks time: 0.10047999769449234 ms
		Find transfer index time: 0.08089599758386612 ms
			Selecting transfer indices time (topk): 2.046976089477539 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 2.165600061416626 ms
		Step preparation time: 0.057760000228881836 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.39020538330078 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05734400078654289 ms
		Confidence score calculation time: 8.132608413696289 ms
		Apply predictions where we have masks time: 0.09728000313043594 ms
		Find transfer index time: 0.07577600330114365 ms
			Selecting transfer indices time (topk): 1.4305280447006226 ms
			Applying transfer index time (where transfer_index): 0.03363199904561043 ms
		update token time: 1.5493119955062866 ms
		Step preparation time: 0.0568000003695488 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.1816635131836 ms
		Gumbel noise and sampling time: 0.16886399686336517 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.055296000093221664 ms
		Confidence score calculation time: 8.128512382507324 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.3608959913253784 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.4786560535430908 ms
		Step preparation time: 0.05718399956822395 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.70976257324219 ms
		Gumbel noise and sampling time: 0.16889600455760956 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.988224029541016 ms
			Confidence score gathering time: 0.05526399984955788 ms
		Confidence score calculation time: 8.143872261047363 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07177600264549255 ms
			Selecting transfer indices time (topk): 1.2963839769363403 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.418239951133728 ms
		Step preparation time: 0.05555199831724167 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.46134185791016 ms
		Gumbel noise and sampling time: 0.1658879965543747 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.915328025817871 ms
			Confidence score gathering time: 0.05337600037455559 ms
		Confidence score calculation time: 8.068927764892578 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07187200337648392 ms
			Selecting transfer indices time (topk): 1.1314560174942017 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.248255968093872 ms
		Step preparation time: 0.05849599838256836 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.97245025634766 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.916543960571289 ms
			Confidence score gathering time: 0.05523199960589409 ms
		Confidence score calculation time: 8.074239730834961 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.2329599857330322 ms
			Applying transfer index time (where transfer_index): 0.05427199974656105 ms
		update token time: 1.3774080276489258 ms
		Step preparation time: 0.05567999929189682 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.60018920898438 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.00153636932373 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.158207893371582 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.3393919467926025 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.457152009010315 ms
		Step preparation time: 0.054655998945236206 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.2616958618164 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.129535675048828 ms
		Apply predictions where we have masks time: 0.10035199671983719 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 0.060256000608205795 ms
			Applying transfer index time (where transfer_index): 0.030880000442266464 ms
		update token time: 0.16896000504493713 ms
Block 2 time: 3016.731201171875 ms
		Step preparation time: 0.05798399820923805 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.4986572265625 ms
		Gumbel noise and sampling time: 0.1740799993276596 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9779839515686035 ms
			Confidence score gathering time: 0.08793599903583527 ms
		Confidence score calculation time: 8.183808326721191 ms
		Apply predictions where we have masks time: 0.12185599654912949 ms
		Find transfer index time: 0.08396799862384796 ms
			Selecting transfer indices time (topk): 3.4315199851989746 ms
			Applying transfer index time (where transfer_index): 0.033824000507593155 ms
		update token time: 3.5543360710144043 ms
		Step preparation time: 0.06239999830722809 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.90182495117188 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.977920055389404 ms
			Confidence score gathering time: 0.060416001826524734 ms
		Confidence score calculation time: 8.148159980773926 ms
		Apply predictions where we have masks time: 0.09523200243711472 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.5482879877090454 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.6660799980163574 ms
		Step preparation time: 0.05395200103521347 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.7646713256836 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.002559661865234 ms
			Confidence score gathering time: 0.053119998425245285 ms
		Confidence score calculation time: 8.156160354614258 ms
		Apply predictions where we have masks time: 0.0902400016784668 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.2318719625473022 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3496960401535034 ms
		Step preparation time: 0.05596800148487091 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.29753875732422 ms
		Gumbel noise and sampling time: 0.1679999977350235 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.058368001133203506 ms
		Confidence score calculation time: 8.143872261047363 ms
		Apply predictions where we have masks time: 0.10239999741315842 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.3392640352249146 ms
			Applying transfer index time (where transfer_index): 0.03788800165057182 ms
		update token time: 1.4776320457458496 ms
		Step preparation time: 0.06191999837756157 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.27584075927734 ms
		Gumbel noise and sampling time: 0.1740799993276596 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9185919761657715 ms
			Confidence score gathering time: 0.06758400052785873 ms
		Confidence score calculation time: 8.104063987731934 ms
		Apply predictions where we have masks time: 0.11673600226640701 ms
		Find transfer index time: 0.08806400001049042 ms
			Selecting transfer indices time (topk): 2.240511894226074 ms
			Applying transfer index time (where transfer_index): 0.03788800165057182 ms
		update token time: 2.378783941268921 ms
		Step preparation time: 0.05641600117087364 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.03711700439453 ms
		Gumbel noise and sampling time: 0.20377600193023682 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.990272045135498 ms
			Confidence score gathering time: 0.0942080020904541 ms
		Confidence score calculation time: 8.217599868774414 ms
		Apply predictions where we have masks time: 0.16784000396728516 ms
		Find transfer index time: 0.10649599879980087 ms
			Selecting transfer indices time (topk): 2.833440065383911 ms
			Applying transfer index time (where transfer_index): 0.04198399931192398 ms
		update token time: 2.995136022567749 ms
		Step preparation time: 0.06966400146484375 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.38774108886719 ms
		Gumbel noise and sampling time: 0.1812479943037033 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.978943824768066 ms
			Confidence score gathering time: 0.07459200173616409 ms
		Confidence score calculation time: 8.167424201965332 ms
		Apply predictions where we have masks time: 0.12406399846076965 ms
		Find transfer index time: 0.11264000087976456 ms
			Selecting transfer indices time (topk): 2.476991891860962 ms
			Applying transfer index time (where transfer_index): 0.03481600061058998 ms
		update token time: 2.598912000656128 ms
		Step preparation time: 0.0676800012588501 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.80217742919922 ms
		Gumbel noise and sampling time: 0.1730560064315796 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.998464107513428 ms
			Confidence score gathering time: 0.06143999844789505 ms
		Confidence score calculation time: 8.163328170776367 ms
		Apply predictions where we have masks time: 0.1043199971318245 ms
		Find transfer index time: 0.08089599758386612 ms
			Selecting transfer indices time (topk): 2.0655999183654785 ms
			Applying transfer index time (where transfer_index): 0.03471999987959862 ms
		update token time: 2.1913599967956543 ms
		Step preparation time: 0.06304000318050385 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.25267028808594 ms
		Gumbel noise and sampling time: 0.1761920005083084 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9767680168151855 ms
			Confidence score gathering time: 0.060447998344898224 ms
		Confidence score calculation time: 8.137727737426758 ms
		Apply predictions where we have masks time: 0.10444799810647964 ms
		Find transfer index time: 0.08182399719953537 ms
			Selecting transfer indices time (topk): 1.951583981513977 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 2.0736639499664307 ms
		Step preparation time: 0.05833600088953972 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.40592193603516 ms
		Gumbel noise and sampling time: 0.1740799993276596 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.07065600156784058 ms
		Confidence score calculation time: 8.180543899536133 ms
		Apply predictions where we have masks time: 0.11264000087976456 ms
		Find transfer index time: 0.07680000364780426 ms
			Selecting transfer indices time (topk): 1.7654399871826172 ms
			Applying transfer index time (where transfer_index): 0.03481600061058998 ms
		update token time: 1.8995200395584106 ms
		Step preparation time: 0.05721599981188774 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.04102325439453 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973951816558838 ms
			Confidence score gathering time: 0.0684799998998642 ms
		Confidence score calculation time: 8.163328170776367 ms
		Apply predictions where we have masks time: 0.11161600053310394 ms
		Find transfer index time: 0.08396799862384796 ms
			Selecting transfer indices time (topk): 1.7173759937286377 ms
			Applying transfer index time (where transfer_index): 0.03683200106024742 ms
		update token time: 1.8513920307159424 ms
		Step preparation time: 0.05817599967122078 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.70767974853516 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.99948787689209 ms
			Confidence score gathering time: 0.05628800019621849 ms
		Confidence score calculation time: 8.164352416992188 ms
		Apply predictions where we have masks time: 0.0920960009098053 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.2872320413589478 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.4078400135040283 ms
		Step preparation time: 0.056095998734235764 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.30025482177734 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05734400078654289 ms
		Confidence score calculation time: 8.141728401184082 ms
		Apply predictions where we have masks time: 0.09126400202512741 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.1571199893951416 ms
			Applying transfer index time (where transfer_index): 0.03283200040459633 ms
		update token time: 1.277951955795288 ms
		Step preparation time: 0.05507199838757515 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.49702453613281 ms
		Gumbel noise and sampling time: 0.17715199291706085 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9779839515686035 ms
			Confidence score gathering time: 0.05939200147986412 ms
		Confidence score calculation time: 8.148991584777832 ms
		Apply predictions where we have masks time: 0.10751999914646149 ms
		Find transfer index time: 0.08191999793052673 ms
			Selecting transfer indices time (topk): 1.435647964477539 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.5544320344924927 ms
		Step preparation time: 0.06313599646091461 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.2303695678711 ms
		Gumbel noise and sampling time: 0.17612800002098083 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.977952003479004 ms
			Confidence score gathering time: 0.058368001133203506 ms
		Confidence score calculation time: 8.141823768615723 ms
		Apply predictions where we have masks time: 0.10147199779748917 ms
		Find transfer index time: 0.0748480036854744 ms
			Selecting transfer indices time (topk): 1.9035840034484863 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 2.021375894546509 ms
		Step preparation time: 0.05539200082421303 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.6974105834961 ms
		Gumbel noise and sampling time: 0.18943999707698822 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.002559661865234 ms
			Confidence score gathering time: 0.062463998794555664 ms
		Confidence score calculation time: 8.179712295532227 ms
		Apply predictions where we have masks time: 0.10633599758148193 ms
		Find transfer index time: 0.08089599758386612 ms
			Selecting transfer indices time (topk): 1.3322240114212036 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.4501760005950928 ms
		Step preparation time: 0.055135998874902725 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.97727966308594 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.12441635131836 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.09523200243711472 ms
			Selecting transfer indices time (topk): 1.3916159868240356 ms
			Applying transfer index time (where transfer_index): 0.032735999673604965 ms
		update token time: 1.509376049041748 ms
		Step preparation time: 0.05913599953055382 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.57670593261719 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.055296000093221664 ms
		Confidence score calculation time: 8.129535675048828 ms
		Apply predictions where we have masks time: 0.0942080020904541 ms
		Find transfer index time: 0.07577600330114365 ms
			Selecting transfer indices time (topk): 1.2900480031967163 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.4090240001678467 ms
		Step preparation time: 0.05740800127387047 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.32489776611328 ms
		Gumbel noise and sampling time: 0.1709440052509308 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.06656000018119812 ms
		Confidence score calculation time: 8.168448448181152 ms
		Apply predictions where we have masks time: 0.10239999741315842 ms
		Find transfer index time: 0.08195199817419052 ms
			Selecting transfer indices time (topk): 1.381376028060913 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.5022079944610596 ms
		Step preparation time: 0.05523199960589409 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.76665496826172 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.0544000007212162 ms
		Confidence score calculation time: 8.130751609802246 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07280000299215317 ms
			Selecting transfer indices time (topk): 1.1458560228347778 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2615679502487183 ms
		Step preparation time: 0.055904000997543335 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.69129943847656 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.981056213378906 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.136639595031738 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.32697594165802 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.4562879800796509 ms
		Step preparation time: 0.05510399863123894 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.56428527832031 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.052319999784231186 ms
		Confidence score calculation time: 8.128512382507324 ms
		Apply predictions where we have masks time: 0.09196799993515015 ms
		Find transfer index time: 0.0809599980711937 ms
			Selecting transfer indices time (topk): 1.2195839881896973 ms
			Applying transfer index time (where transfer_index): 0.032896000891923904 ms
		update token time: 1.3393919467926025 ms
		Step preparation time: 0.05462399870157242 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.31388854980469 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05411199852824211 ms
		Confidence score calculation time: 8.128416061401367 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07264000177383423 ms
			Selecting transfer indices time (topk): 1.1581759452819824 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.285215973854065 ms
		Step preparation time: 0.05558399856090546 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.74095916748047 ms
		Gumbel noise and sampling time: 0.19865599274635315 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.987199783325195 ms
			Confidence score gathering time: 0.07577600330114365 ms
		Confidence score calculation time: 8.183808326721191 ms
		Apply predictions where we have masks time: 0.14339199662208557 ms
		Find transfer index time: 0.0974079966545105 ms
			Selecting transfer indices time (topk): 2.425856113433838 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 2.557919979095459 ms
		Step preparation time: 0.05974400043487549 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.15910339355469 ms
		Gumbel noise and sampling time: 0.17817600071430206 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.056832313537598 ms
			Confidence score gathering time: 0.08694399893283844 ms
		Confidence score calculation time: 8.28825569152832 ms
		Apply predictions where we have masks time: 0.11475200206041336 ms
		Find transfer index time: 0.08908800035715103 ms
			Selecting transfer indices time (topk): 2.8926401138305664 ms
			Applying transfer index time (where transfer_index): 0.03891199827194214 ms
		update token time: 3.0351359844207764 ms
		Step preparation time: 0.06265600025653839 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.02947235107422 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974847793579102 ms
			Confidence score gathering time: 0.06128000095486641 ms
		Confidence score calculation time: 8.157183647155762 ms
		Apply predictions where we have masks time: 0.1013759970664978 ms
		Find transfer index time: 0.07680000364780426 ms
			Selecting transfer indices time (topk): 1.6874879598617554 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.819648027420044 ms
		Step preparation time: 0.061983998864889145 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.46063995361328 ms
		Gumbel noise and sampling time: 0.1802240014076233 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.979008197784424 ms
			Confidence score gathering time: 0.0708480030298233 ms
		Confidence score calculation time: 8.167424201965332 ms
		Apply predictions where we have masks time: 0.12595200538635254 ms
		Find transfer index time: 0.09216000139713287 ms
			Selecting transfer indices time (topk): 2.194495916366577 ms
			Applying transfer index time (where transfer_index): 0.036959998309612274 ms
		update token time: 2.327552080154419 ms
		Step preparation time: 0.0681919977068901 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.67151641845703 ms
		Gumbel noise and sampling time: 0.17395199835300446 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9779839515686035 ms
			Confidence score gathering time: 0.05939200147986412 ms
		Confidence score calculation time: 8.141823768615723 ms
		Apply predictions where we have masks time: 0.09811200201511383 ms
		Find transfer index time: 0.07788799703121185 ms
			Selecting transfer indices time (topk): 1.987488031387329 ms
			Applying transfer index time (where transfer_index): 0.03891199827194214 ms
		update token time: 2.1237759590148926 ms
		Step preparation time: 0.06403200328350067 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.3280029296875 ms
		Gumbel noise and sampling time: 0.16883200407028198 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973728179931641 ms
			Confidence score gathering time: 0.06540799885988235 ms
		Confidence score calculation time: 8.151040077209473 ms
		Apply predictions where we have masks time: 0.10540799796581268 ms
		Find transfer index time: 0.08601599931716919 ms
			Selecting transfer indices time (topk): 1.5605759620666504 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.6957440376281738 ms
		Step preparation time: 0.0628800019621849 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.34150695800781 ms
		Gumbel noise and sampling time: 0.17919999361038208 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9779839515686035 ms
			Confidence score gathering time: 0.05929600074887276 ms
		Confidence score calculation time: 8.165375709533691 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07475200295448303 ms
			Selecting transfer indices time (topk): 1.2431360483169556 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3609600067138672 ms
		Step preparation time: 0.05516799911856651 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.94755554199219 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.191904067993164 ms
		Apply predictions where we have masks time: 0.09120000153779984 ms
		Find transfer index time: 0.08499199897050858 ms
			Selecting transfer indices time (topk): 1.334272027015686 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.4510079622268677 ms
		Step preparation time: 0.054336000233888626 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.04771423339844 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.07884799689054489 ms
		Confidence score calculation time: 8.170495986938477 ms
		Apply predictions where we have masks time: 0.09401600062847137 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 0.05929600074887276 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 0.16896000504493713 ms
Block 3 time: 3061.480712890625 ms
		Step preparation time: 0.05795200169086456 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.71673583984375 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973696231842041 ms
			Confidence score gathering time: 0.061535999178886414 ms
		Confidence score calculation time: 8.135680198669434 ms
		Apply predictions where we have masks time: 0.10649599879980087 ms
		Find transfer index time: 0.0756480023264885 ms
			Selecting transfer indices time (topk): 3.290208101272583 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 3.408895969390869 ms
		Step preparation time: 0.08934400230646133 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.40364837646484 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.06473600119352341 ms
		Confidence score calculation time: 8.147968292236328 ms
		Apply predictions where we have masks time: 0.09830400347709656 ms
		Find transfer index time: 0.07577600330114365 ms
			Selecting transfer indices time (topk): 1.5843199491500854 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.7029119729995728 ms
		Step preparation time: 0.055424001067876816 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.31005096435547 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.06451199948787689 ms
		Confidence score calculation time: 8.143808364868164 ms
		Apply predictions where we have masks time: 0.10121600329875946 ms
		Find transfer index time: 0.08294399827718735 ms
			Selecting transfer indices time (topk): 1.5421439409255981 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.6773120164871216 ms
		Step preparation time: 0.056223999708890915 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.724609375 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.004608154296875 ms
			Confidence score gathering time: 0.05734400078654289 ms
		Confidence score calculation time: 8.17353630065918 ms
		Apply predictions where we have masks time: 0.09116800129413605 ms
		Find transfer index time: 0.08294399827718735 ms
			Selecting transfer indices time (topk): 1.6660480499267578 ms
			Applying transfer index time (where transfer_index): 0.038015998899936676 ms
		update token time: 1.8012160062789917 ms
		Step preparation time: 0.06224000081419945 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.9849624633789 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.990272045135498 ms
			Confidence score gathering time: 0.058368001133203506 ms
		Confidence score calculation time: 8.174400329589844 ms
		Apply predictions where we have masks time: 0.09523200243711472 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.2492799758911133 ms
			Applying transfer index time (where transfer_index): 0.03280000016093254 ms
		update token time: 1.3661760091781616 ms
		Step preparation time: 0.05455999821424484 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.72767639160156 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9779839515686035 ms
			Confidence score gathering time: 0.05516799911856651 ms
		Confidence score calculation time: 8.135680198669434 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07363200187683105 ms
			Selecting transfer indices time (topk): 1.433568000793457 ms
			Applying transfer index time (where transfer_index): 0.03788800165057182 ms
		update token time: 1.5656960010528564 ms
		Step preparation time: 0.06652799993753433 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.6266860961914 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.129504203796387 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.3281279802322388 ms
			Applying transfer index time (where transfer_index): 0.04912000149488449 ms
		update token time: 1.4837759733200073 ms
		Step preparation time: 0.06444799900054932 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.08589172363281 ms
		Gumbel noise and sampling time: 0.17510400712490082 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.977888107299805 ms
			Confidence score gathering time: 0.06864000111818314 ms
		Confidence score calculation time: 8.171520233154297 ms
		Apply predictions where we have masks time: 0.11468800157308578 ms
		Find transfer index time: 0.0888959988951683 ms
			Selecting transfer indices time (topk): 2.0664000511169434 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 2.1872639656066895 ms
		Step preparation time: 0.06601600348949432 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.32844543457031 ms
		Gumbel noise and sampling time: 0.1730560064315796 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.983104228973389 ms
			Confidence score gathering time: 0.07046400010585785 ms
		Confidence score calculation time: 8.164352416992188 ms
		Apply predictions where we have masks time: 0.10751999914646149 ms
		Find transfer index time: 0.07872000336647034 ms
			Selecting transfer indices time (topk): 1.9496959447860718 ms
			Applying transfer index time (where transfer_index): 0.03286400064826012 ms
		update token time: 2.0736000537872314 ms
		Step preparation time: 0.06339199841022491 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.67660522460938 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.022175788879395 ms
			Confidence score gathering time: 0.056352000683546066 ms
		Confidence score calculation time: 8.179712295532227 ms
		Apply predictions where we have masks time: 0.09520000219345093 ms
		Find transfer index time: 0.07680000364780426 ms
			Selecting transfer indices time (topk): 1.4489599466323853 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.569599986076355 ms
		Step preparation time: 0.05769599974155426 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.21126556396484 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.05430399999022484 ms
		Confidence score calculation time: 8.132608413696289 ms
		Apply predictions where we have masks time: 0.0942080020904541 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.2750400304794312 ms
			Applying transfer index time (where transfer_index): 0.03481600061058998 ms
		update token time: 1.418239951133728 ms
		Step preparation time: 0.055615998804569244 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.6328353881836 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.055135998874902725 ms
		Confidence score calculation time: 8.131584167480469 ms
		Apply predictions where we have masks time: 0.09017600119113922 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.274880051612854 ms
			Applying transfer index time (where transfer_index): 0.0318400003015995 ms
		update token time: 1.394495964050293 ms
		Step preparation time: 0.05651199817657471 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.32681274414062 ms
		Gumbel noise and sampling time: 0.1719679981470108 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9759039878845215 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.136672019958496 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.1767040491104126 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.294368028640747 ms
		Step preparation time: 0.060864001512527466 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.04083251953125 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.05632000043988228 ms
		Confidence score calculation time: 8.13548755645752 ms
		Apply predictions where we have masks time: 0.10649599879980087 ms
		Find transfer index time: 0.08191999793052673 ms
			Selecting transfer indices time (topk): 1.3537280559539795 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.4898879528045654 ms
		Step preparation time: 0.061535999178886414 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.92288208007812 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.993343830108643 ms
			Confidence score gathering time: 0.05939200147986412 ms
		Confidence score calculation time: 8.163328170776367 ms
		Apply predictions where we have masks time: 0.10239999741315842 ms
		Find transfer index time: 0.08287999778985977 ms
			Selecting transfer indices time (topk): 1.4549440145492554 ms
			Applying transfer index time (where transfer_index): 0.03577600046992302 ms
		update token time: 1.58515202999115 ms
		Step preparation time: 0.061216000467538834 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.9615707397461 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.052736282348633 ms
			Confidence score gathering time: 0.05628800019621849 ms
		Confidence score calculation time: 8.217599868774414 ms
		Apply predictions where we have masks time: 0.09523200243711472 ms
		Find transfer index time: 0.07465600222349167 ms
			Selecting transfer indices time (topk): 1.3199360370635986 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.438912034034729 ms
		Step preparation time: 0.05632000043988228 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.22803497314453 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.1244478225708 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.206112027168274 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3230719566345215 ms
		Step preparation time: 0.054655998945236206 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.57103729248047 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.055296000093221664 ms
		Confidence score calculation time: 8.130559921264648 ms
		Apply predictions where we have masks time: 0.09116800129413605 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.4233280420303345 ms
			Applying transfer index time (where transfer_index): 0.03788800165057182 ms
		update token time: 1.5820800065994263 ms
		Step preparation time: 0.06233600154519081 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.68624114990234 ms
		Gumbel noise and sampling time: 0.17401599884033203 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.0655359998345375 ms
		Confidence score calculation time: 8.172415733337402 ms
		Apply predictions where we have masks time: 0.10956799983978271 ms
		Find transfer index time: 0.08396799862384796 ms
			Selecting transfer indices time (topk): 1.593183994293213 ms
			Applying transfer index time (where transfer_index): 0.035999998450279236 ms
		update token time: 1.7273279428482056 ms
		Step preparation time: 0.06204799935221672 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.19923400878906 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.055135998874902725 ms
		Confidence score calculation time: 8.133631706237793 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07366400212049484 ms
			Selecting transfer indices time (topk): 1.2922879457473755 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.4090240001678467 ms
		Step preparation time: 0.0551999993622303 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.16121673583984 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.984127998352051 ms
			Confidence score gathering time: 0.059487998485565186 ms
		Confidence score calculation time: 8.153311729431152 ms
		Apply predictions where we have masks time: 0.10358399897813797 ms
		Find transfer index time: 0.07996799796819687 ms
			Selecting transfer indices time (topk): 1.3967360258102417 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.5278719663619995 ms
		Step preparation time: 0.0549440011382103 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.79126739501953 ms
		Gumbel noise and sampling time: 0.21094399690628052 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.074239730834961 ms
			Confidence score gathering time: 0.06348799914121628 ms
		Confidence score calculation time: 8.253439903259277 ms
		Apply predictions where we have masks time: 0.10956799983978271 ms
		Find transfer index time: 0.08499199897050858 ms
			Selecting transfer indices time (topk): 1.6650240421295166 ms
			Applying transfer index time (where transfer_index): 0.037856001406908035 ms
		update token time: 1.8001919984817505 ms
		Step preparation time: 0.06272000074386597 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.51251220703125 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.040448188781738 ms
			Confidence score gathering time: 0.05827200040221214 ms
		Confidence score calculation time: 8.228863716125488 ms
		Apply predictions where we have masks time: 0.10255999863147736 ms
		Find transfer index time: 0.08294399827718735 ms
			Selecting transfer indices time (topk): 1.4438400268554688 ms
			Applying transfer index time (where transfer_index): 0.035840000957250595 ms
		update token time: 1.5738879442214966 ms
		Step preparation time: 0.0639680027961731 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.29702758789062 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05411199852824211 ms
		Confidence score calculation time: 8.127488136291504 ms
		Apply predictions where we have masks time: 0.0910400003194809 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.2082560062408447 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3322240114212036 ms
		Step preparation time: 0.055615998804569244 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.69535827636719 ms
		Gumbel noise and sampling time: 0.19251200556755066 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.984127998352051 ms
			Confidence score gathering time: 0.0798719972372055 ms
		Confidence score calculation time: 8.183808326721191 ms
		Apply predictions where we have masks time: 0.15241600573062897 ms
		Find transfer index time: 0.10239999741315842 ms
			Selecting transfer indices time (topk): 2.561984062194824 ms
			Applying transfer index time (where transfer_index): 0.03891199827194214 ms
		update token time: 2.703360080718994 ms
		Step preparation time: 0.06668800115585327 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.77581024169922 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.97705602645874 ms
			Confidence score gathering time: 0.06963200122117996 ms
		Confidence score calculation time: 8.16431999206543 ms
		Apply predictions where we have masks time: 0.11468800157308578 ms
		Find transfer index time: 0.08908800035715103 ms
			Selecting transfer indices time (topk): 2.1923840045928955 ms
			Applying transfer index time (where transfer_index): 0.03791999816894531 ms
		update token time: 2.3306241035461426 ms
		Step preparation time: 0.06409599632024765 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.64771270751953 ms
		Gumbel noise and sampling time: 0.17295999825000763 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9779839515686035 ms
			Confidence score gathering time: 0.06739199906587601 ms
		Confidence score calculation time: 8.164352416992188 ms
		Apply predictions where we have masks time: 0.11059200018644333 ms
		Find transfer index time: 0.08614400029182434 ms
			Selecting transfer indices time (topk): 1.5656960010528564 ms
			Applying transfer index time (where transfer_index): 0.036768000572919846 ms
		update token time: 1.7000000476837158 ms
		Step preparation time: 0.06384000182151794 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.69731140136719 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.055296000093221664 ms
		Confidence score calculation time: 8.164352416992188 ms
		Apply predictions where we have masks time: 0.09516800194978714 ms
		Find transfer index time: 0.07680000364780426 ms
			Selecting transfer indices time (topk): 1.3731839656829834 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.4880640506744385 ms
		Step preparation time: 0.05459199845790863 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.3095703125 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.127488136291504 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07577600330114365 ms
			Selecting transfer indices time (topk): 1.3015040159225464 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.4294079542160034 ms
		Step preparation time: 0.06268800050020218 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.1662368774414 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033247947692871 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.184831619262695 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07388799637556076 ms
			Selecting transfer indices time (topk): 1.2082560062408447 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3271039724349976 ms
		Step preparation time: 0.06188800185918808 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.13536071777344 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.032256126403809 ms
			Confidence score gathering time: 0.06143999844789505 ms
		Confidence score calculation time: 8.204352378845215 ms
		Apply predictions where we have masks time: 0.10649599879980087 ms
		Find transfer index time: 0.08399999886751175 ms
			Selecting transfer indices time (topk): 1.6465920209884644 ms
			Applying transfer index time (where transfer_index): 0.03593600168824196 ms
		update token time: 1.7817599773406982 ms
		Step preparation time: 0.0623680017888546 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.93791961669922 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.0533440001308918 ms
		Confidence score calculation time: 8.188863754272461 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 0.05939200147986412 ms
			Applying transfer index time (where transfer_index): 0.030719999223947525 ms
		update token time: 0.16896000504493713 ms
Block 4 time: 3103.144287109375 ms
		Step preparation time: 0.06960000097751617 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.75865936279297 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.976928234100342 ms
			Confidence score gathering time: 0.06233600154519081 ms
		Confidence score calculation time: 8.143872261047363 ms
		Apply predictions where we have masks time: 0.10249599814414978 ms
		Find transfer index time: 0.07571200281381607 ms
			Selecting transfer indices time (topk): 3.2194559574127197 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 3.340287923812866 ms
		Step preparation time: 0.06467200070619583 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.53478240966797 ms
		Gumbel noise and sampling time: 0.16998399794101715 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.060416001826524734 ms
		Confidence score calculation time: 8.197183609008789 ms
		Apply predictions where we have masks time: 0.1056319996714592 ms
		Find transfer index time: 0.0788159966468811 ms
			Selecting transfer indices time (topk): 1.7643840312957764 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.8823039531707764 ms
		Step preparation time: 0.05648000165820122 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.71247863769531 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05734400078654289 ms
		Confidence score calculation time: 8.133631706237793 ms
		Apply predictions where we have masks time: 0.09728000313043594 ms
		Find transfer index time: 0.07577600330114365 ms
			Selecting transfer indices time (topk): 1.6936639547348022 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.8165440559387207 ms
		Step preparation time: 0.056384000927209854 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.5511703491211 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.05718399956822395 ms
		Confidence score calculation time: 8.130751609802246 ms
		Apply predictions where we have masks time: 0.1013759970664978 ms
		Find transfer index time: 0.07884799689054489 ms
			Selecting transfer indices time (topk): 1.7336959838867188 ms
			Applying transfer index time (where transfer_index): 0.03280000016093254 ms
		update token time: 1.8534400463104248 ms
		Step preparation time: 0.0586559996008873 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.40201568603516 ms
		Gumbel noise and sampling time: 0.17504000663757324 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.06860800087451935 ms
		Confidence score calculation time: 8.150015830993652 ms
		Apply predictions where we have masks time: 0.12390399724245071 ms
		Find transfer index time: 0.08585599809885025 ms
			Selecting transfer indices time (topk): 2.5712640285491943 ms
			Applying transfer index time (where transfer_index): 0.03481600061058998 ms
		update token time: 2.695199966430664 ms
		Step preparation time: 0.0589120015501976 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.07440185546875 ms
		Gumbel noise and sampling time: 0.18329599499702454 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.976831912994385 ms
			Confidence score gathering time: 0.0655359998345375 ms
		Confidence score calculation time: 8.155136108398438 ms
		Apply predictions where we have masks time: 0.11264000087976456 ms
		Find transfer index time: 0.088128000497818 ms
			Selecting transfer indices time (topk): 2.011136054992676 ms
			Applying transfer index time (where transfer_index): 0.03788800165057182 ms
		update token time: 2.146336078643799 ms
		Step preparation time: 0.05728000029921532 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.94364929199219 ms
		Gumbel noise and sampling time: 0.17612800002098083 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.035327911376953 ms
			Confidence score gathering time: 0.07065600156784058 ms
		Confidence score calculation time: 8.220671653747559 ms
		Apply predictions where we have masks time: 0.12390399724245071 ms
		Find transfer index time: 0.09113600105047226 ms
			Selecting transfer indices time (topk): 2.203648090362549 ms
			Applying transfer index time (where transfer_index): 0.03392000123858452 ms
		update token time: 2.3295040130615234 ms
		Step preparation time: 0.058687999844551086 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.14556884765625 ms
		Gumbel noise and sampling time: 0.1730560064315796 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.06255999952554703 ms
		Confidence score calculation time: 8.144895553588867 ms
		Apply predictions where we have masks time: 0.10652799904346466 ms
		Find transfer index time: 0.09001599997282028 ms
			Selecting transfer indices time (topk): 2.0952320098876953 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 2.2168960571289062 ms
		Step preparation time: 0.05750399827957153 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.91951751708984 ms
		Gumbel noise and sampling time: 0.17510400712490082 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.06639999896287918 ms
		Confidence score calculation time: 8.217599868774414 ms
		Apply predictions where we have masks time: 0.11788800358772278 ms
		Find transfer index time: 0.08396799862384796 ms
			Selecting transfer indices time (topk): 2.2026240825653076 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 2.323456048965454 ms
		Step preparation time: 0.06188800185918808 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.22953796386719 ms
		Gumbel noise and sampling time: 0.16070400178432465 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05734400078654289 ms
		Confidence score calculation time: 8.130687713623047 ms
		Apply predictions where we have masks time: 0.09523200243711472 ms
		Find transfer index time: 0.07680000364780426 ms
			Selecting transfer indices time (topk): 1.7539199590682983 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.8749439716339111 ms
		Step preparation time: 0.0578560009598732 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.35852813720703 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.127488136291504 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.07577600330114365 ms
			Selecting transfer indices time (topk): 1.4315520524978638 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.5482879877090454 ms
		Step preparation time: 0.055743999779224396 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.7251205444336 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975840091705322 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.126463890075684 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.3619199991226196 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.5011839866638184 ms
		Step preparation time: 0.05567999929189682 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.55769348144531 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.05430399999022484 ms
		Confidence score calculation time: 8.143872261047363 ms
		Apply predictions where we have masks time: 0.09203200042247772 ms
		Find transfer index time: 0.07286400347948074 ms
			Selecting transfer indices time (topk): 1.1796480417251587 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.299456000328064 ms
		Step preparation time: 0.05423999950289726 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.30316925048828 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.125439643859863 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07180800288915634 ms
			Selecting transfer indices time (topk): 1.1466879844665527 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2636159658432007 ms
		Step preparation time: 0.055615998804569244 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.94649505615234 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.128512382507324 ms
		Apply predictions where we have masks time: 0.09027200192213058 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.3078399896621704 ms
			Applying transfer index time (where transfer_index): 0.03187200054526329 ms
		update token time: 1.4243839979171753 ms
		Step preparation time: 0.05459199845790863 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.90179443359375 ms
		Gumbel noise and sampling time: 0.16889600455760956 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.059904098510742 ms
			Confidence score gathering time: 0.051263999193906784 ms
		Confidence score calculation time: 8.210432052612305 ms
		Apply predictions where we have masks time: 0.0942080020904541 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.1663360595703125 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.282047986984253 ms
		Step preparation time: 0.05628800019621849 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.22480010986328 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.979008197784424 ms
			Confidence score gathering time: 0.05411199852824211 ms
		Confidence score calculation time: 8.135680198669434 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.1786240339279175 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.3136320114135742 ms
		Step preparation time: 0.05363199859857559 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.48432159423828 ms
		Gumbel noise and sampling time: 0.16892799735069275 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.12441635131836 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07187200337648392 ms
			Selecting transfer indices time (topk): 1.1254719495773315 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2451839447021484 ms
		Step preparation time: 0.05423999950289726 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.74934387207031 ms
		Gumbel noise and sampling time: 0.16777600347995758 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.128512382507324 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.1601920127868652 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.2789759635925293 ms
		Step preparation time: 0.05417599901556969 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.52044677734375 ms
		Gumbel noise and sampling time: 0.16883200407028198 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.971839904785156 ms
			Confidence score gathering time: 0.06143999844789505 ms
		Confidence score calculation time: 8.145919799804688 ms
		Apply predictions where we have masks time: 0.10342399775981903 ms
		Find transfer index time: 0.08089599758386612 ms
			Selecting transfer indices time (topk): 1.264639973640442 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.4007359743118286 ms
		Step preparation time: 0.05539200082421303 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.36399841308594 ms
		Gumbel noise and sampling time: 0.1740799993276596 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9779839515686035 ms
			Confidence score gathering time: 0.06672000139951706 ms
		Confidence score calculation time: 8.159232139587402 ms
		Apply predictions where we have masks time: 0.11878400295972824 ms
		Find transfer index time: 0.07884799689054489 ms
			Selecting transfer indices time (topk): 1.960960030555725 ms
			Applying transfer index time (where transfer_index): 0.03481600061058998 ms
		update token time: 2.0870718955993652 ms
		Step preparation time: 0.08137600123882294 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.39897918701172 ms
		Gumbel noise and sampling time: 0.1730560064315796 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.06451199948787689 ms
		Confidence score calculation time: 8.154111862182617 ms
		Apply predictions where we have masks time: 0.11052799969911575 ms
		Find transfer index time: 0.08499199897050858 ms
			Selecting transfer indices time (topk): 1.960960030555725 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 2.096127986907959 ms
		Step preparation time: 0.06348799914121628 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.3986587524414 ms
		Gumbel noise and sampling time: 0.17401599884033203 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.06348799914121628 ms
		Confidence score calculation time: 8.153087615966797 ms
		Apply predictions where we have masks time: 0.11043199896812439 ms
		Find transfer index time: 0.08604799956083298 ms
			Selecting transfer indices time (topk): 1.8431999683380127 ms
			Applying transfer index time (where transfer_index): 0.04403200000524521 ms
		update token time: 1.9875839948654175 ms
		Step preparation time: 0.06419199705123901 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.4836196899414 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.06348799914121628 ms
		Confidence score calculation time: 8.212479591369629 ms
		Apply predictions where we have masks time: 0.10547199845314026 ms
		Find transfer index time: 0.08508799970149994 ms
			Selecting transfer indices time (topk): 1.551360011100769 ms
			Applying transfer index time (where transfer_index): 0.03702399879693985 ms
		update token time: 1.6814080476760864 ms
		Step preparation time: 0.06294400244951248 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.33280181884766 ms
		Gumbel noise and sampling time: 0.1740799993276596 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.976960182189941 ms
			Confidence score gathering time: 0.060416001826524734 ms
		Confidence score calculation time: 8.148991584777832 ms
		Apply predictions where we have masks time: 0.10444799810647964 ms
		Find transfer index time: 0.08396799862384796 ms
			Selecting transfer indices time (topk): 1.315775990486145 ms
			Applying transfer index time (where transfer_index): 0.03270399942994118 ms
		update token time: 1.4334080219268799 ms
		Step preparation time: 0.060896001756191254 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.10393524169922 ms
		Gumbel noise and sampling time: 0.1708800047636032 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.06143999844789505 ms
		Confidence score calculation time: 8.150015830993652 ms
		Apply predictions where we have masks time: 0.10239999741315842 ms
		Find transfer index time: 0.0828159973025322 ms
			Selecting transfer indices time (topk): 1.457152009010315 ms
			Applying transfer index time (where transfer_index): 0.03705599904060364 ms
		update token time: 1.5902719497680664 ms
		Step preparation time: 0.06147199869155884 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.05359649658203 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.05939200147986412 ms
		Confidence score calculation time: 8.147968292236328 ms
		Apply predictions where we have masks time: 0.10444799810647964 ms
		Find transfer index time: 0.08294399827718735 ms
			Selecting transfer indices time (topk): 1.3485440015792847 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.4807039499282837 ms
		Step preparation time: 0.06060799956321716 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.20057678222656 ms
		Gumbel noise and sampling time: 0.1669439971446991 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.035327911376953 ms
			Confidence score gathering time: 0.060416001826524734 ms
		Confidence score calculation time: 8.208255767822266 ms
		Apply predictions where we have masks time: 0.11072000116109848 ms
		Find transfer index time: 0.08278399705886841 ms
			Selecting transfer indices time (topk): 1.4325759410858154 ms
			Applying transfer index time (where transfer_index): 0.03680000081658363 ms
		update token time: 1.5656960010528564 ms
		Step preparation time: 0.0865280032157898 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.98429107666016 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973696231842041 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.127391815185547 ms
		Apply predictions where we have masks time: 0.09523200243711472 ms
		Find transfer index time: 0.07276800274848938 ms
			Selecting transfer indices time (topk): 1.5228480100631714 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.6406400203704834 ms
		Step preparation time: 0.05500800162553787 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.22886657714844 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.056832313537598 ms
			Confidence score gathering time: 0.05961599946022034 ms
		Confidence score calculation time: 8.22771167755127 ms
		Apply predictions where we have masks time: 0.10239999741315842 ms
		Find transfer index time: 0.08294399827718735 ms
			Selecting transfer indices time (topk): 1.5075199604034424 ms
			Applying transfer index time (where transfer_index): 0.035840000957250595 ms
		update token time: 1.640447974205017 ms
		Step preparation time: 0.06115199998021126 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.36822509765625 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.048640251159668 ms
			Confidence score gathering time: 0.060416001826524734 ms
		Confidence score calculation time: 8.224767684936523 ms
		Apply predictions where we have masks time: 0.10438399761915207 ms
		Find transfer index time: 0.08191999793052673 ms
			Selecting transfer indices time (topk): 1.3905919790267944 ms
			Applying transfer index time (where transfer_index): 0.03587200120091438 ms
		update token time: 1.525823950767517 ms
		Step preparation time: 0.061503998935222626 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.24297332763672 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.994368076324463 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.14303970336914 ms
		Apply predictions where we have masks time: 0.09110400080680847 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 0.060416001826524734 ms
			Applying transfer index time (where transfer_index): 0.030719999223947525 ms
		update token time: 0.16896000504493713 ms
Block 5 time: 3139.5810546875 ms
		Step preparation time: 0.05721599981188774 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.5191650390625 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.06563200056552887 ms
		Confidence score calculation time: 8.154975891113281 ms
		Apply predictions where we have masks time: 0.10751999914646149 ms
		Find transfer index time: 0.07884799689054489 ms
			Selecting transfer indices time (topk): 2.564095973968506 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 2.6808319091796875 ms
		Step preparation time: 0.05484800040721893 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.29952239990234 ms
		Gumbel noise and sampling time: 0.16601599752902985 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.18892765045166 ms
		Apply predictions where we have masks time: 0.09318400174379349 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.316864013671875 ms
			Applying transfer index time (where transfer_index): 0.032575998455286026 ms
		update token time: 1.435647964477539 ms
		Step preparation time: 0.05987200140953064 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.49727630615234 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.05939200147986412 ms
		Confidence score calculation time: 8.155136108398438 ms
		Apply predictions where we have masks time: 0.12083200365304947 ms
		Find transfer index time: 0.09318400174379349 ms
			Selecting transfer indices time (topk): 1.4008320569992065 ms
			Applying transfer index time (where transfer_index): 0.036896001547575 ms
		update token time: 1.5349760055541992 ms
		Step preparation time: 0.05427199974656105 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.65145874023438 ms
		Gumbel noise and sampling time: 0.16915200650691986 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973855972290039 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.127552032470703 ms
		Apply predictions where we have masks time: 0.0902400016784668 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.2912319898605347 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.411072015762329 ms
		Step preparation time: 0.053727999329566956 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.55721282958984 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.07065600156784058 ms
		Confidence score calculation time: 8.159232139587402 ms
		Apply predictions where we have masks time: 0.1013759970664978 ms
		Find transfer index time: 0.0798719972372055 ms
			Selecting transfer indices time (topk): 1.2953599691390991 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.427456021308899 ms
		Step preparation time: 0.06140799820423126 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.64179229736328 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05209600180387497 ms
		Confidence score calculation time: 8.128512382507324 ms
		Apply predictions where we have masks time: 0.09830400347709656 ms
		Find transfer index time: 0.07184000313282013 ms
			Selecting transfer indices time (topk): 1.2594879865646362 ms
			Applying transfer index time (where transfer_index): 0.036639999598264694 ms
		update token time: 1.3926399946212769 ms
		Step preparation time: 0.05430399999022484 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.49702453613281 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.138655662536621 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.2769279479980469 ms
			Applying transfer index time (where transfer_index): 0.0326399989426136 ms
		update token time: 1.3957120180130005 ms
		Step preparation time: 0.05423999950289726 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.5052490234375 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.035327911376953 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.189056396484375 ms
		Apply predictions where we have masks time: 0.0899839997291565 ms
		Find transfer index time: 0.06963200122117996 ms
			Selecting transfer indices time (topk): 1.2187520265579224 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3354560136795044 ms
		Step preparation time: 0.0541439987719059 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.41260528564453 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.032256126403809 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.185983657836914 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.149888038635254 ms
			Applying transfer index time (where transfer_index): 0.032575998455286026 ms
		update token time: 1.2666879892349243 ms
		Step preparation time: 0.0549440011382103 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.00003051757812 ms
		Gumbel noise and sampling time: 0.169855996966362 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.147968292236328 ms
		Apply predictions where we have masks time: 0.09206400066614151 ms
		Find transfer index time: 0.07254400104284286 ms
			Selecting transfer indices time (topk): 1.2431360483169556 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.3619199991226196 ms
		Step preparation time: 0.05392000079154968 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.79440307617188 ms
		Gumbel noise and sampling time: 0.16675199568271637 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9738240242004395 ms
			Confidence score gathering time: 0.05321599915623665 ms
		Confidence score calculation time: 8.126463890075684 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07081600278615952 ms
			Selecting transfer indices time (topk): 1.2492799758911133 ms
			Applying transfer index time (where transfer_index): 0.03187200054526329 ms
		update token time: 1.363968014717102 ms
		Step preparation time: 0.05993599817156792 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.88777923583984 ms
		Gumbel noise and sampling time: 0.16780799627304077 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.022015571594238 ms
			Confidence score gathering time: 0.05104000121355057 ms
		Confidence score calculation time: 8.170304298400879 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.235967993736267 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3629440069198608 ms
		Step preparation time: 0.05446400120854378 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.1662368774414 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.984127998352051 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.137727737426758 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07273600250482559 ms
			Selecting transfer indices time (topk): 1.1038719415664673 ms
			Applying transfer index time (where transfer_index): 0.03270399942994118 ms
		update token time: 1.2216320037841797 ms
		Step preparation time: 0.054816000163555145 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.34044647216797 ms
		Gumbel noise and sampling time: 0.16883200407028198 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.971936225891113 ms
			Confidence score gathering time: 0.050175998359918594 ms
		Confidence score calculation time: 8.122367858886719 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.1385279893875122 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2554240226745605 ms
		Step preparation time: 0.054655998945236206 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.64009857177734 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.975935935974121 ms
			Confidence score gathering time: 0.05142400041222572 ms
		Confidence score calculation time: 8.132608413696289 ms
		Apply predictions where we have masks time: 0.08912000060081482 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.2431360483169556 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3629440069198608 ms
		Step preparation time: 0.05484800040721893 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.77875518798828 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.971839904785156 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.127488136291504 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.0798719972372055 ms
			Selecting transfer indices time (topk): 1.2247040271759033 ms
			Applying transfer index time (where transfer_index): 0.03500799834728241 ms
		update token time: 1.3578239679336548 ms
		Step preparation time: 0.05407999828457832 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.60835266113281 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.05939200147986412 ms
		Confidence score calculation time: 8.144800186157227 ms
		Apply predictions where we have masks time: 0.11363200098276138 ms
		Find transfer index time: 0.08009599894285202 ms
			Selecting transfer indices time (topk): 1.1233279705047607 ms
			Applying transfer index time (where transfer_index): 0.03270399942994118 ms
		update token time: 1.2410880327224731 ms
		Step preparation time: 0.056832000613212585 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.5316162109375 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973728179931641 ms
			Confidence score gathering time: 0.053279999643564224 ms
		Confidence score calculation time: 8.128576278686523 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.222656011581421 ms
			Applying transfer index time (where transfer_index): 0.0326399989426136 ms
		update token time: 1.340448021888733 ms
		Step preparation time: 0.054816000163555145 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.37490844726562 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.128512382507324 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.112064003944397 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2289600372314453 ms
		Step preparation time: 0.05459199845790863 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.51500701904297 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.20736026763916 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.2390400171279907 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.35971200466156 ms
		Step preparation time: 0.05353600159287453 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.46348571777344 ms
		Gumbel noise and sampling time: 0.16889600455760956 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.051392000168561935 ms
		Confidence score calculation time: 8.184831619262695 ms
		Apply predictions where we have masks time: 0.0899839997291565 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.1048959493637085 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.222656011581421 ms
		Step preparation time: 0.057440001517534256 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.10848236083984 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.186944007873535 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07174400240182877 ms
			Selecting transfer indices time (topk): 1.1745280027389526 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.2904000282287598 ms
		Step preparation time: 0.054655998945236206 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.88121795654297 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.125472068786621 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.124351978302002 ms
			Applying transfer index time (where transfer_index): 0.03481600061058998 ms
		update token time: 1.2544000148773193 ms
		Step preparation time: 0.05353600159287453 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.0799331665039 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.032256126403809 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.187904357910156 ms
		Apply predictions where we have masks time: 0.08908800035715103 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.1478400230407715 ms
			Applying transfer index time (where transfer_index): 0.031808000057935715 ms
		update token time: 1.2636159658432007 ms
		Step preparation time: 0.05536000058054924 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.12425231933594 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.06390380859375 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.219679832458496 ms
		Apply predictions where we have masks time: 0.09113600105047226 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.1622400283813477 ms
			Applying transfer index time (where transfer_index): 0.03177599981427193 ms
		update token time: 1.2840960025787354 ms
		Step preparation time: 0.05392000079154968 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.23747253417969 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.981056213378906 ms
			Confidence score gathering time: 0.05225599929690361 ms
		Confidence score calculation time: 8.134655952453613 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07260800153017044 ms
			Selecting transfer indices time (topk): 1.18886399269104 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3046079874038696 ms
		Step preparation time: 0.05452800169587135 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.57337951660156 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.06140799820423126 ms
		Confidence score calculation time: 8.208383560180664 ms
		Apply predictions where we have masks time: 0.10239999741315842 ms
		Find transfer index time: 0.08089599758386612 ms
			Selecting transfer indices time (topk): 1.246016025543213 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3670400381088257 ms
		Step preparation time: 0.054496001452207565 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.39775848388672 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.137727737426758 ms
		Apply predictions where we have masks time: 0.09212800115346909 ms
		Find transfer index time: 0.09219200164079666 ms
			Selecting transfer indices time (topk): 1.114240050315857 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.23580801486969 ms
		Step preparation time: 0.054816000163555145 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.63145446777344 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974880218505859 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.127488136291504 ms
		Apply predictions where we have masks time: 0.09011200070381165 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.269919991493225 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3895679712295532 ms
		Step preparation time: 0.0560000017285347 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.98505401611328 ms
		Gumbel noise and sampling time: 0.16787199676036835 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.032256126403809 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.183808326721191 ms
		Apply predictions where we have masks time: 0.09027200192213058 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.2163200378417969 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.3405439853668213 ms
		Step preparation time: 0.05507199838757515 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.95001220703125 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.035327911376953 ms
			Confidence score gathering time: 0.05833600088953972 ms
		Confidence score calculation time: 8.20531177520752 ms
		Apply predictions where we have masks time: 0.10342399775981903 ms
		Find transfer index time: 0.08191999793052673 ms
			Selecting transfer indices time (topk): 1.2298239469528198 ms
			Applying transfer index time (where transfer_index): 0.032896000891923904 ms
		update token time: 1.3496320247650146 ms
		Step preparation time: 0.06083200126886368 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.66876983642578 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.9738240242004395 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.136704444885254 ms
		Apply predictions where we have masks time: 0.09001599997282028 ms
		Find transfer index time: 0.07257600128650665 ms
			Selecting transfer indices time (topk): 0.05939200147986412 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 0.16896000504493713 ms
Block 6 time: 3154.192138671875 ms
		Step preparation time: 0.05753599852323532 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.60297393798828 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.974912166595459 ms
			Confidence score gathering time: 0.058368001133203506 ms
		Confidence score calculation time: 8.140800476074219 ms
		Apply predictions where we have masks time: 0.08499199897050858 ms
		Find transfer index time: 0.07577600330114365 ms
			Selecting transfer indices time (topk): 2.2599680423736572 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 2.382848024368286 ms
		Step preparation time: 0.05478399991989136 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.60435485839844 ms
		Gumbel noise and sampling time: 0.16777600347995758 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.052032001316547394 ms
		Confidence score calculation time: 8.184000015258789 ms
		Apply predictions where we have masks time: 0.08601599931716919 ms
		Find transfer index time: 0.07180800288915634 ms
			Selecting transfer indices time (topk): 1.1785279512405396 ms
			Applying transfer index time (where transfer_index): 0.0318400003015995 ms
		update token time: 1.2983360290527344 ms
		Step preparation time: 0.05417599901556969 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.55750274658203 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.972864151000977 ms
			Confidence score gathering time: 0.060256000608205795 ms
		Confidence score calculation time: 8.132608413696289 ms
		Apply predictions where we have masks time: 0.08489599823951721 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.1458560228347778 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.265663981437683 ms
		Step preparation time: 0.054687999188899994 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.65907287597656 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.05718399956822395 ms
		Confidence score calculation time: 8.20019245147705 ms
		Apply predictions where we have masks time: 0.09728000313043594 ms
		Find transfer index time: 0.08089599758386612 ms
			Selecting transfer indices time (topk): 1.3649920225143433 ms
			Applying transfer index time (where transfer_index): 0.03686400130391121 ms
		update token time: 1.4972480535507202 ms
		Step preparation time: 0.05398400127887726 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.84483337402344 ms
		Gumbel noise and sampling time: 0.17203199863433838 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.036352157592773 ms
			Confidence score gathering time: 0.05939200147986412 ms
		Confidence score calculation time: 8.212479591369629 ms
		Apply predictions where we have masks time: 0.09830400347709656 ms
		Find transfer index time: 0.08086399734020233 ms
			Selecting transfer indices time (topk): 1.3506560325622559 ms
			Applying transfer index time (where transfer_index): 0.031968001276254654 ms
		update token time: 1.4684159755706787 ms
		Step preparation time: 0.0607680007815361 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.5344009399414 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.187904357910156 ms
		Apply predictions where we have masks time: 0.08499199897050858 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.321984052658081 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.4367040395736694 ms
		Step preparation time: 0.062111999839544296 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.5137939453125 ms
		Gumbel noise and sampling time: 0.17100800573825836 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.036352157592773 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.196096420288086 ms
		Apply predictions where we have masks time: 0.08499199897050858 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.2390719652175903 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3578239679336548 ms
		Step preparation time: 0.060864001512527466 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.53084564208984 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034175872802734 ms
			Confidence score gathering time: 0.05020799860358238 ms
		Confidence score calculation time: 8.182784080505371 ms
		Apply predictions where we have masks time: 0.08601599931716919 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.2257280349731445 ms
			Applying transfer index time (where transfer_index): 0.033695999532938004 ms
		update token time: 1.346560001373291 ms
		Step preparation time: 0.06108799949288368 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.5125732421875 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.05212799832224846 ms
		Confidence score calculation time: 8.186880111694336 ms
		Apply predictions where we have masks time: 0.08396799862384796 ms
		Find transfer index time: 0.07161600142717361 ms
			Selecting transfer indices time (topk): 1.264639973640442 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.385472059249878 ms
		Step preparation time: 0.061503998935222626 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.1938247680664 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033151626586914 ms
			Confidence score gathering time: 0.05337600037455559 ms
		Confidence score calculation time: 8.188960075378418 ms
		Apply predictions where we have masks time: 0.0870399996638298 ms
		Find transfer index time: 0.07161600142717361 ms
			Selecting transfer indices time (topk): 1.2021759748458862 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.3178880214691162 ms
		Step preparation time: 0.06115199998021126 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.30595397949219 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.03228759765625 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.185855865478516 ms
		Apply predictions where we have masks time: 0.08595199882984161 ms
		Find transfer index time: 0.07171200215816498 ms
			Selecting transfer indices time (topk): 1.227776050567627 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.3455359935760498 ms
		Step preparation time: 0.0615679994225502 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.31871795654297 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.032256126403809 ms
			Confidence score gathering time: 0.052319999784231186 ms
		Confidence score calculation time: 8.186880111694336 ms
		Apply predictions where we have masks time: 0.08499199897050858 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.2275840044021606 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3434879779815674 ms
		Step preparation time: 0.06207999959588051 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.25888061523438 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.032256126403809 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.186880111694336 ms
		Apply predictions where we have masks time: 0.08499199897050858 ms
		Find transfer index time: 0.07081600278615952 ms
			Selecting transfer indices time (topk): 1.2513279914855957 ms
			Applying transfer index time (where transfer_index): 0.032607998698949814 ms
		update token time: 1.369088053703308 ms
		Step preparation time: 0.06252799928188324 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.1707534790039 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.05212799832224846 ms
		Confidence score calculation time: 8.183808326721191 ms
		Apply predictions where we have masks time: 0.08483199775218964 ms
		Find transfer index time: 0.07267200201749802 ms
			Selecting transfer indices time (topk): 1.1048320531845093 ms
			Applying transfer index time (where transfer_index): 0.03379200026392937 ms
		update token time: 1.2247040271759033 ms
		Step preparation time: 0.06159999966621399 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.89244842529297 ms
		Gumbel noise and sampling time: 0.16803200542926788 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 7.973887920379639 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.127488136291504 ms
		Apply predictions where we have masks time: 0.08396799862384796 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.1244800090789795 ms
			Applying transfer index time (where transfer_index): 0.032735999673604965 ms
		update token time: 1.2421120405197144 ms
		Step preparation time: 0.061503998935222626 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.15411376953125 ms
		Gumbel noise and sampling time: 0.1679999977350235 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.187904357910156 ms
		Apply predictions where we have masks time: 0.08505599945783615 ms
		Find transfer index time: 0.07075200229883194 ms
			Selecting transfer indices time (topk): 1.1008000373840332 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.218559980392456 ms
		Step preparation time: 0.061535999178886414 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.11180877685547 ms
		Gumbel noise and sampling time: 0.17190399765968323 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.050687789916992 ms
			Confidence score gathering time: 0.062463998794555664 ms
		Confidence score calculation time: 8.21555233001709 ms
		Apply predictions where we have masks time: 0.11161600053310394 ms
		Find transfer index time: 0.09120000153779984 ms
			Selecting transfer indices time (topk): 2.2722558975219727 ms
			Applying transfer index time (where transfer_index): 0.03788800165057182 ms
		update token time: 2.407423973083496 ms
		Step preparation time: 0.07411199808120728 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.31552124023438 ms
		Gumbel noise and sampling time: 0.1740799993276596 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.037376403808594 ms
			Confidence score gathering time: 0.060416001826524734 ms
		Confidence score calculation time: 8.20633602142334 ms
		Apply predictions where we have masks time: 0.09216000139713287 ms
		Find transfer index time: 0.088128000497818 ms
			Selecting transfer indices time (topk): 1.9763200283050537 ms
			Applying transfer index time (where transfer_index): 0.03788800165057182 ms
		update token time: 2.1134719848632812 ms
		Step preparation time: 0.07110399752855301 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.3272933959961 ms
		Gumbel noise and sampling time: 0.16995200514793396 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.035327911376953 ms
			Confidence score gathering time: 0.058368001133203506 ms
		Confidence score calculation time: 8.195072174072266 ms
		Apply predictions where we have masks time: 0.08825600147247314 ms
		Find transfer index time: 0.07884799689054489 ms
			Selecting transfer indices time (topk): 1.465343952178955 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.5841280221939087 ms
		Step preparation time: 0.07072000205516815 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.33462524414062 ms
		Gumbel noise and sampling time: 0.16892799735069275 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.058368001133203506 ms
		Confidence score calculation time: 8.195072174072266 ms
		Apply predictions where we have masks time: 0.08793599903583527 ms
		Find transfer index time: 0.07571200281381607 ms
			Selecting transfer indices time (topk): 1.3281279802322388 ms
			Applying transfer index time (where transfer_index): 0.03359999880194664 ms
		update token time: 1.44595205783844 ms
		Step preparation time: 0.06249599903821945 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.27747344970703 ms
		Gumbel noise and sampling time: 0.1687680035829544 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.05427199974656105 ms
		Confidence score calculation time: 8.187968254089355 ms
		Apply predictions where we have masks time: 0.0891840010881424 ms
		Find transfer index time: 0.07286400347948074 ms
			Selecting transfer indices time (topk): 1.4438400268554688 ms
			Applying transfer index time (where transfer_index): 0.03596799820661545 ms
		update token time: 1.5738879442214966 ms
		Step preparation time: 0.06220800057053566 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.28707122802734 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.187904357910156 ms
		Apply predictions where we have masks time: 0.08582399785518646 ms
		Find transfer index time: 0.07372800260782242 ms
			Selecting transfer indices time (topk): 1.134592056274414 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2533760070800781 ms
		Step preparation time: 0.06185600161552429 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.17340850830078 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.186880111694336 ms
		Apply predictions where we have masks time: 0.08396799862384796 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.1499520540237427 ms
			Applying transfer index time (where transfer_index): 0.03174399957060814 ms
		update token time: 1.269760012626648 ms
		Step preparation time: 0.06224000081419945 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.22358703613281 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.032256126403809 ms
			Confidence score gathering time: 0.05411199852824211 ms
		Confidence score calculation time: 8.18892765045166 ms
		Apply predictions where we have masks time: 0.08601599931716919 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.16428804397583 ms
			Applying transfer index time (where transfer_index): 0.03283200040459633 ms
		update token time: 1.283136010169983 ms
		Step preparation time: 0.06022400036454201 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.1719970703125 ms
		Gumbel noise and sampling time: 0.16784000396728516 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.05407999828457832 ms
		Confidence score calculation time: 8.187840461730957 ms
		Apply predictions where we have masks time: 0.08396799862384796 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.1621439456939697 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.2799999713897705 ms
		Step preparation time: 0.06006399914622307 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 73.99750518798828 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.186880111694336 ms
		Apply predictions where we have masks time: 0.08499199897050858 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.18886399269104 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.305408000946045 ms
		Step preparation time: 0.061535999178886414 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.0755844116211 ms
		Gumbel noise and sampling time: 0.16793599724769592 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.05119999870657921 ms
		Confidence score calculation time: 8.184831619262695 ms
		Apply predictions where we have masks time: 0.08396799862384796 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.2472319602966309 ms
			Applying transfer index time (where transfer_index): 0.0318400003015995 ms
		update token time: 1.368064045906067 ms
		Step preparation time: 0.06038400158286095 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.13689422607422 ms
		Gumbel noise and sampling time: 0.1669120043516159 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.192000389099121 ms
		Apply predictions where we have masks time: 0.08723200112581253 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 1.1868159770965576 ms
			Applying transfer index time (where transfer_index): 0.03177599981427193 ms
		update token time: 1.3054720163345337 ms
		Step preparation time: 0.06860800087451935 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.13410949707031 ms
		Gumbel noise and sampling time: 0.16896000504493713 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034272193908691 ms
			Confidence score gathering time: 0.052319999784231186 ms
		Confidence score calculation time: 8.18892765045166 ms
		Apply predictions where we have masks time: 0.08601599931716919 ms
		Find transfer index time: 0.09216000139713287 ms
			Selecting transfer indices time (topk): 1.385472059249878 ms
			Applying transfer index time (where transfer_index): 0.035999998450279236 ms
		update token time: 1.5185920000076294 ms
		Step preparation time: 0.06207999959588051 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.13740539550781 ms
		Gumbel noise and sampling time: 0.16790400445461273 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.032256126403809 ms
			Confidence score gathering time: 0.0594559982419014 ms
		Confidence score calculation time: 8.202239990234375 ms
		Apply predictions where we have masks time: 0.10547199845314026 ms
		Find transfer index time: 0.07065600156784058 ms
			Selecting transfer indices time (topk): 1.372223973274231 ms
			Applying transfer index time (where transfer_index): 0.037696000188589096 ms
		update token time: 1.5054080486297607 ms
		Step preparation time: 0.0626240000128746 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.1595230102539 ms
		Gumbel noise and sampling time: 0.1677439957857132 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.033280372619629 ms
			Confidence score gathering time: 0.053247999399900436 ms
		Confidence score calculation time: 8.1909761428833 ms
		Apply predictions where we have masks time: 0.08601599931716919 ms
		Find transfer index time: 0.0727040022611618 ms
			Selecting transfer indices time (topk): 1.2441600561141968 ms
			Applying transfer index time (where transfer_index): 0.03276799991726875 ms
		update token time: 1.3701119422912598 ms
		Step preparation time: 0.06220800057053566 ms
forward args:
	input_ids: torch.Size([1, 325])
	input_embeddings: None
	attention_mask: None
	attention_bias: None
	past_key_values: None
	use_cache: False
	last_logits_only: False
	output_hidden_states: None
	replace_position: None

forward output:
	logits: torch.Size([1, 325, 126464])
	attn_key_values: None
	hidden_states: None
--------------------------------------------------
		Model inference time: 74.13938903808594 ms
		Gumbel noise and sampling time: 0.1677439957857132 ms
			=> type of logits: torch.bfloat16
			Softmax calculation time: 8.034303665161133 ms
			Confidence score gathering time: 0.05222399905323982 ms
		Confidence score calculation time: 8.185855865478516 ms
		Apply predictions where we have masks time: 0.08601599931716919 ms
		Find transfer index time: 0.07168000191450119 ms
			Selecting transfer indices time (topk): 0.05939200147986412 ms
			Applying transfer index time (where transfer_index): 0.03155200183391571 ms
		update token time: 0.16896000504493713 ms
Block 7 time: 3188.499755859375 ms
Final response: To determine how many double-flips Tyler did, we need to follow these steps:

Step 1: Identify the number of triple-flips Jen did.
Jen did sixteen triple-flips.

Step 2: Determine how many times Tyler flipped in the air.
Tyler flipped in the air half the number of times Jen did. Therefore, we calculate:
\[ \text{Number of flips Tyler did} = \frac{16}{2} = 8 \]

Step 3: Calculate the number of double-flips Tyler did.
Since Tyler is practicing the double-flip and he did a total of 8 flips, we can find the number of double-flips by dividing the total number of flips by the number of flips per double-flip:
\[ \text{Number of double-flips Tyler did} = \frac{8}{2} = 4 \]

Thus, the number of double-flips Tyler did is \(\boxed{4}\).
